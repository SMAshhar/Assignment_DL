{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flowers Recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python390jvsc74a57bd04657b0f8676137db8f77784ecc505075a6d6f547c0bf96eb839d3f8b887897c4",
      "display_name": "Python 3.9.0 64-bit"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXgJ6uT1NydQ"
      },
      "source": [
        "Assignment: Flowers Recognition <br>\r\n",
        "Dataset Description:<br>\r\n",
        "\r\n",
        "This dataset contains 4242 images of flowers.<br>\r\n",
        "The data collection is based on the data flicr, google images, yandex images.<br>\r\n",
        "You can use this datastet to recognize plants from the photo.<br>\r\n",
        "\r\n",
        "Attribute Information:<br>\r\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\r\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\r\n",
        "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\r\n",
        "This is a Multiclass Classification Problem.<br>\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7vy-ktuOKJH"
      },
      "source": [
        "WORKFLOW : <br>\r\n",
        "Load Data <br>\r\n",
        "Split into 60 and 40 ratio.<br>\r\n",
        "Encode labels.<br>\r\n",
        "Create Model<br>\r\n",
        "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\r\n",
        "Train the Model.<br>\r\n",
        "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\r\n",
        "Prediction should be > 85%<br>\r\n",
        "Evaluation Step<br>\r\n",
        "Prediction<br>\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri3Bg5qfPRic"
      },
      "source": [
        "Data : <br>\r\n",
        "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTtg3WuGTA1o"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers, models, optimizers, Sequential"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WinError 2] The system cannot find the file specified: 'Flowersdata/'\nd:\\PIAIC\\Quarter 2\\Assignments\\3. Deep learning\\AI-Q2-learning-resources\\DLAssignments\\Solving\\Flowersdata\n"
          ]
        }
      ],
      "source": [
        "cd Flowersdata/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining function\n",
        "\n",
        "flowers = ['./daisy', './dandelion', './rose', './sunflower', './tulip']\n",
        "length = []\n",
        "\n",
        "def read_image(directory):\n",
        "    for img in glob.glob(directory+'/*.jpg'):\n",
        "        image = cv2.imread(img)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        resized_img = cv2.resize(image/255.0, (100,100))\n",
        "        yield resized_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./daisy\n",
            "./dandelion\n",
            "./rose\n",
            "./sunflower\n",
            "./tulip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4323, 100, 100), [769, 1052, 784, 734, 984])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "for x in flowers:\n",
        "    print(x)\n",
        "    y = np.array(list(read_image(x)))\n",
        "    if x == './daisy':\n",
        "        data = y  \n",
        "    else:\n",
        "        data = np.vstack((data, y))\n",
        "    length.append(len(y))\n",
        "\n",
        "data.shape, length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [4.],\n",
              "       [4.],\n",
              "       [4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "i = 1\n",
        "targets = np.ones((length[0], 1))*0\n",
        "for x in length[1:]:\n",
        "    targets = np.vstack((targets, np.ones((x , 1)) * i))\n",
        "    i += 1\n",
        "\n",
        "targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "targets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(769, 1052, 784, 734, 984)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "(targets == 0).sum(), (targets == 1).sum(), (targets == 2).sum(), (targets == 3).sum(), (targets == 4).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(111)\n",
        "mask = np.random.rand(len(data)) < 0.6\n",
        "train_data = data[mask]\n",
        "test_data = data[~mask]\n",
        "train_targets = targets[mask]\n",
        "test_targets = targets[~mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2606, 100, 100), (1717, 100, 100), (2606, 1), (1717, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "train_data.shape, test_data.shape, train_targets.shape, test_targets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images = train_data.reshape((2606,100*100))\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_data.reshape((1717,100*100))\n",
        "test_images = test_images.astype('float32')\n",
        "\n",
        "# train_images, test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(100*100,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "27/27 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.2365\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.2368\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.2492\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.2377\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.2533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1decd00f3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.fit(train_images, train_targets, epochs = 5, batch_size = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.2487\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.24868957698345184]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model.evaluate(test_images, test_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}